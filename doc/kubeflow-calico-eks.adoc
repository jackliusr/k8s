= Setup kubeflow on eks in cost effective way
:TOC:

Favor configuration file than command line. 

== Environment

eks 1.18
kubeflow v1.2

[#eks-cluster-cfg-file]
==  eks cluster configuration file
 
 keywords: maxPodsPerNode, pod density and ec2 instance types
 
[source, yaml]
----

---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: kf-dev
  region: ap-southeast-1
cloudWatch:
  clusterLogging:
    enableTypes:
    - api
iam:
  withOIDC: true
  serviceAccounts:
  - metadata:
      name: s3-reader
      # if no namespace is set, "default" will be used;
      # the namespace will be created if it doesn't exist already
      namespace: backend-apps
      labels: {aws-usage: "application"}
    attachPolicyARNs:
    - "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess"
  - metadata:
      name: cache-access
      namespace: backend-apps
      labels: {aws-usage: "application"}
    attachPolicyARNs:
    - "arn:aws:iam::aws:policy/AmazonDynamoDBReadOnlyAccess"
    - "arn:aws:iam::aws:policy/AmazonElastiCacheFullAccess"
  - metadata:
      name: cluster-autoscaler
      namespace: kube-system
      labels: {aws-usage: "cluster-ops"}
    attachPolicy: # inline policy can be defined along with `attachPolicyARNs`
      Version: "2012-10-17"
      Statement:
      - Effect: Allow
        Action:
        - "autoscaling:DescribeAutoScalingGroups"
        - "autoscaling:DescribeAutoScalingInstances"
        - "autoscaling:DescribeLaunchConfigurations"
        - "autoscaling:DescribeTags"
        - "autoscaling:SetDesiredCapacity"
        - "autoscaling:TerminateInstanceInAutoScalingGroup"
        - "ec2:DescribeLaunchTemplateVersions"
        Resource: '*'

nodeGroups:
  - name: "ng-1"
    tags:
      # EC2 tags required for cluster-autoscaler auto-discovery
      k8s.io/cluster-autoscaler/enabled: "true"
      k8s.io/cluster-autoscaler/kf-dev: "owned"
    desiredCapacity: 2
    instanceType: m5.large
    maxPodsPerNode: 100
    availabilityZones: [ap-southeast-1a]
    iam:
      withAddonPolicies:
        autoScaler: true
    ssh:
      publicKeyPath: ~/.ssh/jack_key.pub
      
----
 
== Create eks cluster and Setup up Calico

https://docs.projectcalico.org/getting-started/kubernetes/managed-public-cloud/eks

Assuming the cluster configuration file is kf-dev-cluster.yaml

[source, bash]
----
eksctl create cluster -f kf-dev-cluster.yaml --without-nodegroup
kubectl delete daemonset -n kube-system aws-node
kubectl apply -f https://docs.projectcalico.org/manifests/calico-vxlan.yaml
eksctl create nodegroup -f kf-dev-cluster.yaml
----

== Check if the cluster works

[source, bash]
----
kubectl create deployment nginx --image=nginx --replicas 2 --port 80
kubectl expose deployment nginx
kubectl run tmp-$RANDOM --image=alpine --rm -it --restart=Never -- wget -qO- nginx
#the above wget command should be successfully run without any error such as timeout etc.
----

== Setup kubeflow

https://www.kubeflow.org/docs/aws/deploy/install-kubeflow/

Change the kustomization.yaml files in respective folders according to the following patch files before running kfctl apply -V -f kfctl_aws.yaml


[source, yaml]
----
---
# ./metacontroller/sts-metacontroller-patch.yaml
- op: replace
  path: /spec/template/spec/containers/0/resources/requests/cpu
  value: "100m"
  
---
# ./cert-manager/cert-manager-webhook-patch.yaml
- op: add
  path: /spec/template/spec/hostNetwork
  value: true

---
#./istio-stack/istio-galley-patch.yaml
- op: add
  path: /spec/template/spec/hostNetwork
  value: true

---
#./istio-stack/istio-sidecar-injector.yaml
- op: add
  path: /spec/template/spec/hostNetwork
  value: true
 
---
#./istio-stack/istio-telemetry-patch.yaml

- op: replace
  path: /spec/template/spec/containers/0/resources/requests/cpu
  value: "100m"
  
---
# ./istio-stack/istio-pilot-patch.yaml

- op: replace
  path: /spec/template/spec/containers/0/resources/requests/cpu
  value: "100m"

----

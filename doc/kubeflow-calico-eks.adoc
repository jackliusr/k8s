= Setup kubeflow on eks in cost effective way
== create eks cluster
 
 keywords: maxPodsPerNode, pod density and ec2 instance types
 
[source, yaml]
----

---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: kf-dev
  region: ap-southeast-1
cloudWatch:
  clusterLogging:
    enableTypes:
    - api
iam:
  withOIDC: true
  serviceAccounts:
  - metadata:
      name: s3-reader
      # if no namespace is set, "default" will be used;
      # the namespace will be created if it doesn't exist already
      namespace: backend-apps
      labels: {aws-usage: "application"}
    attachPolicyARNs:
    - "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess"
  - metadata:
      name: cache-access
      namespace: backend-apps
      labels: {aws-usage: "application"}
    attachPolicyARNs:
    - "arn:aws:iam::aws:policy/AmazonDynamoDBReadOnlyAccess"
    - "arn:aws:iam::aws:policy/AmazonElastiCacheFullAccess"
  - metadata:
      name: cluster-autoscaler
      namespace: kube-system
      labels: {aws-usage: "cluster-ops"}
    attachPolicy: # inline policy can be defined along with `attachPolicyARNs`
      Version: "2012-10-17"
      Statement:
      - Effect: Allow
        Action:
        - "autoscaling:DescribeAutoScalingGroups"
        - "autoscaling:DescribeAutoScalingInstances"
        - "autoscaling:DescribeLaunchConfigurations"
        - "autoscaling:DescribeTags"
        - "autoscaling:SetDesiredCapacity"
        - "autoscaling:TerminateInstanceInAutoScalingGroup"
        - "ec2:DescribeLaunchTemplateVersions"
        Resource: '*'

nodeGroups:
  - name: "ng-1"
    tags:
      # EC2 tags required for cluster-autoscaler auto-discovery
      k8s.io/cluster-autoscaler/enabled: "true"
      k8s.io/cluster-autoscaler/kf-dev: "owned"
    desiredCapacity: 2
    instanceType: m5.large
    maxPodsPerNode: 100
    availabilityZones: [ap-southeast-1a]
    iam:
      withAddonPolicies:
        autoScaler: true
    ssh:
      publicKeyPath: ~/.ssh/jack_key.pub
      
----
 
== Setup up Calico

https://docs.projectcalico.org/getting-started/kubernetes/managed-public-cloud/eks

=== command line

as in https://docs.projectcalico.org/getting-started/kubernetes/managed-public-cloud/eks

=== config file

Issues: 

* can't communicate with other pods

[source, bash]
----
kubectl delete daemonset -n kube-system aws-node
# ssh to nodes and rm /etc/cni/net.d/10-aws.conflist
# maybe should follow the instructions to clean up fully at https://www.weave.works/docs/net/latest/kubernetes/kube-addon/#eks 
kubectl apply -f https://docs.projectcalico.org/manifests/calico-vxlan.yaml
----
== Setup kubeflow

https://www.kubeflow.org/docs/aws/deploy/install-kubeflow/

Change the kustomization.yaml files in respective folders according to the following patch files before running kfctl apply -V -f kfctl_aws.yaml


[source, yaml]
----
---
# ./metacontroller/sts-metacontroller-patch.yaml
- op: replace
  path: /spec/template/spec/containers/0/resources/requests/cpu
  value: "100m"
  
---
# ./cert-manager/cert-manager-webhook-patch.yaml
- op: add
  path: /spec/template/spec/hostNetwork
  value: true

---
#./istio-stack/istio-galley-patch.yaml
- op: add
  path: /spec/template/spec/hostNetwork
  value: true

---
#./istio-stack/istio-sidecar-injector.yaml
- op: add
  path: /spec/template/spec/hostNetwork
  value: true
 
---
#./istio-stack/istio-telemetry-patch.yaml

- op: replace
  path: /spec/template/spec/containers/0/resources/requests/cpu
  value: "100m"
  
---
# ./istio-stack/istio-pilot-patch.yaml

- op: replace
  path: /spec/template/spec/containers/0/resources/requests/cpu
  value: "100m"

----
